# CNS Raspador

[![Python 3.7+](https://img.shields.io/badge/python-3.7+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

Um raspador completo para coleta, download e extraÃ§Ã£o de texto das resoluÃ§Ãµes do **Conselho Nacional de SaÃºde (CNS)** do Brasil.

## ğŸ“‹ Funcionalidades

- **ğŸ•·ï¸ Web Scraping**: Coleta metadados de todas as resoluÃ§Ãµes CNS por ano (1988-2025)
- **ğŸ“¥ Download de PDFs**: Download automÃ¡tico dos documentos PDF das resoluÃ§Ãµes
- **ğŸ“„ ExtraÃ§Ã£o de Texto**: ExtraÃ§Ã£o de texto completo dos PDFs utilizando OCR
- **ğŸ”— Matching Inteligente**: CombinaÃ§Ã£o automÃ¡tica entre metadados e textos extraÃ­dos
- **ğŸ“Š RelatÃ³rios Detalhados**: EstatÃ­sticas completas do processo de coleta
- **ğŸ’¾ Formato CSV**: ExportaÃ§Ã£o em formato estruturado para anÃ¡lise posterior

## ğŸš€ InstalaÃ§Ã£o

### 1. Clone o repositÃ³rio
```bash
git clone https://github.com/seu-usuario/cns-raspador.git
cd cns-raspador
```

### 2. Crie um ambiente virtual (recomendado)
```bash
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows
```

### 3. Instale as dependÃªncias
```bash
pip install -r requirements.txt
```

## ğŸ“– Como Usar

### Interface de Linha de Comando

O projeto oferece uma interface CLI completa atravÃ©s do arquivo `main.py`:

```bash
# Exibir ajuda
python main.py -h

# Verificar status do projeto
python main.py status

# Executar pipeline completo (recomendado)
python main.py full

# Ou executar etapas individuais:
python main.py scrape                    # 1. Coletar metadados
python main.py download [arquivo.csv]    # 2. Baixar PDFs
python main.py extract [arquivo.csv]     # 3. Extrair textos
```

### Uso ProgramÃ¡tico

```python
from src.scraper import coletar_todos_dados, baixar_todos_pdfs
from src.text_extractor import criar_base_completa_com_textos

# 1. Coletar dados das resoluÃ§Ãµes
resolution_data = coletar_todos_dados()

# 2. Baixar PDFs (opcional)
baixar_todos_pdfs('cns_resolucoes_completo_20241225_120000.csv')

# 3. Criar base completa com textos
complete_db = criar_base_completa_com_textos()
```

## ğŸ“ Estrutura do Projeto

```
cns-raspador/
â”œâ”€â”€ src/                          # CÃ³digo fonte
â”‚   â”œâ”€â”€ __init__.py              # InicializaÃ§Ã£o do mÃ³dulo
â”‚   â”œâ”€â”€ scraper.py               # Web scraping e download de PDFs
â”‚   â””â”€â”€ text_extractor.py        # ExtraÃ§Ã£o de texto dos PDFs
â”œâ”€â”€ main.py                      # Interface CLI principal
â”œâ”€â”€ requirements.txt             # DependÃªncias Python
â”œâ”€â”€ README.md                    # Este arquivo
â”œâ”€â”€ .gitignore                   # Arquivos ignorados pelo Git
â””â”€â”€ outputs/                     # Arquivos de saÃ­da (criado automaticamente)
    â”œâ”€â”€ cns_resolucoes_*.csv     # Metadados das resoluÃ§Ãµes
    â”œâ”€â”€ cns_resolucoes_com_textos_*.csv  # Base completa com textos
    â””â”€â”€ pdfs_cns_resolucoes/     # PDFs baixados organizados por ano
```

## ğŸ“Š Dados Coletados

### Metadados (scraper.py)
- **titulo**: TÃ­tulo da resoluÃ§Ã£o
- **link**: URL para o documento PDF
- **descricao**: DescriÃ§Ã£o/resumo da resoluÃ§Ã£o
- **tags**: Tags/categorias separadas por vÃ­rgula
- **data_publicacao**: Data de publicaÃ§Ã£o
- **hora_publicacao**: Hora de publicaÃ§Ã£o
- **ano**: Ano da resoluÃ§Ã£o

### Textos ExtraÃ­dos (text_extractor.py)
- **texto_pdf**: Texto completo extraÃ­do do PDF
- **tamanho_texto_pdf**: NÃºmero de caracteres do texto
- **erro_extracao_pdf**: Indica se houve erro na extraÃ§Ã£o

## âš™ï¸ ConfiguraÃ§Ã£o

### ParÃ¢metros Importantes

- **Anos de coleta**: Por padrÃ£o coleta de 2025 a 1988 (configurÃ¡vel em `gerar_urls_paginas()`)
- **Timeout de download**: 30 segundos por PDF (configurÃ¡vel em `baixar_pdf()`)
- **Limite de pÃ¡ginas**: Sem limite por padrÃ£o (configurÃ¡vel em `extrair_texto_do_pdf()`)
- **Pausa entre requisiÃ§Ãµes**: 1 segundo para scraping, 0.5s para downloads

### PersonalizaÃ§Ã£o

Para modificar os anos de coleta, edite a funÃ§Ã£o `gerar_urls_paginas()` em `src/scraper.py`:

```python
def gerar_urls_paginas():
    return [f'https://www.gov.br/conselho-nacional-de-saude/pt-br/atos-normativos/resolucoes/{ano}' 
            for ano in range(2025, 2000, -1)]  # Apenas de 2025 a 2000
```

## ğŸ“ˆ Performance

- **Coleta de metadados**: ~1-2 segundos por ano
- **Download de PDFs**: ~1-5 segundos por arquivo (varia com tamanho)
- **ExtraÃ§Ã£o de texto**: ~0.5-2 segundos por PDF
- **Total estimado**: 2-4 horas para coleta completa (1988-2025)

### OtimizaÃ§Ãµes Implementadas

- âœ… Salvamentos progressivos a cada 5 anos
- âœ… VerificaÃ§Ã£o de arquivos existentes (pula downloads duplicados)
- âœ… Tratamento robusto de erros com logs detalhados
- âœ… Pausas respeitosas entre requisiÃ§Ãµes
- âœ… Matching inteligente entre metadados e PDFs

## ğŸ› ï¸ DependÃªncias

- **requests**: Para requisiÃ§Ãµes HTTP
- **beautifulsoup4**: Para parsing HTML
- **pandas**: Para manipulaÃ§Ã£o de dados
- **pdfplumber**: Para extraÃ§Ã£o de texto de PDFs

## ğŸ“ Exemplos de Uso

### 1. Coleta RÃ¡pida (Ãºltimos 5 anos)
```python
from src.scraper import gerar_urls_paginas, coletar_dados_pagina

# Modificar temporariamente para apenas anos recentes
urls = [f'https://www.gov.br/conselho-nacional-de-saude/pt-br/atos-normativos/resolucoes/{ano}' 
        for ano in range(2025, 2020, -1)]

data = []
for url in urls:
    year = url.split('/')[-1]
    data.extend(coletar_dados_pagina(url, year))
```

### 2. ExtraÃ§Ã£o de Texto Limitada
```python
from src.text_extractor import criar_base_completa_com_textos

# Limitar a 3 pÃ¡ginas por PDF para processamento mais rÃ¡pido
df = criar_base_completa_com_textos(max_paginas_por_pdf=3)
```

### 3. AnÃ¡lise dos Dados Coletados
```python
import pandas as pd

# Carregar dados completos
df = pd.read_csv('cns_resolucoes_com_textos_20241225_120000.csv')

# EstatÃ­sticas bÃ¡sicas
print(f"Total de resoluÃ§Ãµes: {len(df)}")
print(f"Anos disponÃ­veis: {sorted(df['ano'].unique())}")
print(f"ResoluÃ§Ãµes com texto: {df['tamanho_texto_pdf'].gt(0).sum()}")

# ResoluÃ§Ãµes por ano
print(df['ano'].value_counts().sort_index())

# Buscar por termo especÃ­fico
covid_resolutions = df[df['texto_pdf'].str.contains('COVID', case=False, na=False)]
print(f"ResoluÃ§Ãµes sobre COVID: {len(covid_resolutions)}")
```

## ğŸ¤ ContribuiÃ§Ã£o

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor:

1. FaÃ§a um Fork do projeto
2. Crie uma branch para sua feature (`git checkout -b feature/nova-funcionalidade`)
3. Commit suas mudanÃ§as (`git commit -am 'Adiciona nova funcionalidade'`)
4. Push para a branch (`git push origin feature/nova-funcionalidade`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## âš ï¸ Aviso Legal

Este projeto foi desenvolvido para fins educacionais e de pesquisa. Os dados coletados sÃ£o pÃºblicos e disponibilizados pelo governo brasileiro. Use de forma responsÃ¡vel e respeitando os termos de uso do site do CNS.
